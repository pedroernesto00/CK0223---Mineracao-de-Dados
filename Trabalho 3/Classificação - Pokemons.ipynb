{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo do Trabalho\n",
    "\n",
    "O objetivo desse trabalho é retornar a classe correta de um pokemon tendo como entrada a foto desse pokemon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copy2, rmtree\n",
    "from PIL import Image\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Water       114\n",
       "Normal      105\n",
       "Grass        78\n",
       "Bug          72\n",
       "Fire         53\n",
       "Psychic      53\n",
       "Rock         46\n",
       "Electric     40\n",
       "Poison       34\n",
       "Ground       32\n",
       "Dark         29\n",
       "Fighting     29\n",
       "Ghost        27\n",
       "Dragon       27\n",
       "Steel        26\n",
       "Ice          23\n",
       "Fairy        18\n",
       "Flying        3\n",
       "Name: Type1, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon_df = pd.read_csv('pokemon.csv')\n",
    "pokemon_df.Type1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos acima, temos 18 classes de Pokemon (considerando apenas o Tipo Primário do monstro). Nota-se que há tipos com muitas poucas amostras, o que dificultaria bastante sua predição correta. Para tentarmos melhorar, escolhemos dividir as amostras em 4 classes: Água, Fogo, Normal e Outros. Quando um pokemon possui dois dos tipos (por exemplo, Type1 = Water e Type2 = Normal), fazemos sua inclusão na classe referente ao seu tipo primário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pokemon_water = pokemon_df.loc[((pokemon_df.Type1 != \"Fire\") \n",
    "                               & (pokemon_df.Type1 != \"Normal\") \n",
    "                               & (pokemon_df.Type2 == \"Water\")) | (pokemon_df.Type1 == \"Water\")].copy()\n",
    "\n",
    "pokemon_fire = pokemon_df.loc[((pokemon_df.Type1 != \"Water\") \n",
    "                               & (pokemon_df.Type1 != \"Normal\") \n",
    "                               & (pokemon_df.Type2 == \"Fire\")) | (pokemon_df.Type1 == \"Fire\")].copy()\n",
    "\n",
    "pokemon_normal = pokemon_df.loc[((pokemon_df.Type1 != \"Fire\") \n",
    "                               & (pokemon_df.Type1 != \"Water\") \n",
    "                               & (pokemon_df.Type2 == \"Normal\")) | (pokemon_df.Type1 == \"Normal\")].copy()\n",
    "\n",
    "pokemon_other = pokemon_df.loc[(pokemon_df.Type1 != \"Fire\") \n",
    "                               & (pokemon_df.Type1 != \"Water\") \n",
    "                               & (pokemon_df.Type1 != \"Normal\")\n",
    "                               & (pokemon_df.Type2 != \"Fire\") \n",
    "                               & (pokemon_df.Type2 != \"Water\") \n",
    "                               & (pokemon_df.Type2 != \"Normal\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_dict = {\"Name\" : [], \n",
    "           \"Type\" : []}\n",
    "\n",
    "for pk_name in pokemon_water.Name.values:\n",
    "    pk_dict[\"Name\"].append(pk_name)\n",
    "    pk_dict[\"Type\"].append(\"Water\")\n",
    "    \n",
    "for pk_name in pokemon_fire.Name.values:\n",
    "    pk_dict[\"Name\"].append(pk_name)\n",
    "    pk_dict[\"Type\"].append(\"Fire\")\n",
    "    \n",
    "for pk_name in pokemon_normal.Name.values:\n",
    "    pk_dict[\"Name\"].append(pk_name)\n",
    "    pk_dict[\"Type\"].append(\"Normal\")\n",
    "\n",
    "for pk_name in pokemon_other.Name.values:\n",
    "    pk_dict[\"Name\"].append(pk_name)\n",
    "    pk_dict[\"Type\"].append(\"Others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squirtle</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wartortle</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blastoise</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psyduck</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>golduck</td>\n",
       "      <td>Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>naganadel</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>stakataka</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>zeraora</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>meltan</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>melmetal</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name    Type\n",
       "0     squirtle   Water\n",
       "1    wartortle   Water\n",
       "2    blastoise   Water\n",
       "3      psyduck   Water\n",
       "4      golduck   Water\n",
       "..         ...     ...\n",
       "804  naganadel  Others\n",
       "805  stakataka  Others\n",
       "806    zeraora  Others\n",
       "807     meltan  Others\n",
       "808   melmetal  Others\n",
       "\n",
       "[809 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_types_df = pd.DataFrame(pk_dict)\n",
    "pk_types_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos agora que as classes ficaram com mais amostras, mesmos que Others ainda se sobressaia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Others    509\n",
       "Water     129\n",
       "Normal    107\n",
       "Fire       64\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_types_df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando path da imagem na row correspondente\n",
    "\n",
    "Algumas imagens possuem fundo transparente, então incluimos nelas um fundo branco e as transformamos de PNG para JPG. É importante notar que, quando a pasta já existe, a excluímos e a criamos de novo. Isso pode ser feito apenas uma vez, mas deixamos para manter esse passo de conversão no notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pokemon_imgs = os.listdir('images')\n",
    "\n",
    "if not os.path.exists('converted_images/'):\n",
    "    os.mkdir('converted_images/')\n",
    "else:\n",
    "    rmtree('converted_images/')\n",
    "    os.mkdir('converted_images/') \n",
    "\n",
    "sorted_imgs = pokemon_imgs.copy()\n",
    "for pokemon in pokemon_imgs:\n",
    "    pk_img = Image.open(f'images/{pokemon}')\n",
    "    \n",
    "    pk_img = pk_img.convert(\"RGBA\")\n",
    "    background = background = Image.new('RGB', pk_img.size, (256,256,256))\n",
    "    background.paste(pk_img, mask=pk_img.split()[3])\n",
    "    \n",
    "    background.save(f'converted_images/{pokemon.split(\".\")[0]}.jpg')\n",
    "    \n",
    "    pokemon_name = pokemon.split('.')[0]\n",
    "    index = pokemon_df[pk_types_df.Name == pokemon_name].index.values[0]\n",
    "    sorted_imgs[index] = f'{pokemon.split(\".\")[0]}.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazemos a ligação correta entre o caminho da imagem de um pokemon e sua posição na tabela de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Pokemon Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squirtle</td>\n",
       "      <td>Water</td>\n",
       "      <td>squirtle.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wartortle</td>\n",
       "      <td>Water</td>\n",
       "      <td>wartortle.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blastoise</td>\n",
       "      <td>Water</td>\n",
       "      <td>blastoise.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psyduck</td>\n",
       "      <td>Water</td>\n",
       "      <td>psyduck.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>golduck</td>\n",
       "      <td>Water</td>\n",
       "      <td>golduck.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>naganadel</td>\n",
       "      <td>Others</td>\n",
       "      <td>naganadel.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>stakataka</td>\n",
       "      <td>Others</td>\n",
       "      <td>stakataka.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>zeraora</td>\n",
       "      <td>Others</td>\n",
       "      <td>zeraora.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>meltan</td>\n",
       "      <td>Others</td>\n",
       "      <td>meltan.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>melmetal</td>\n",
       "      <td>Others</td>\n",
       "      <td>melmetal.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name    Type  Pokemon Image\n",
       "0     squirtle   Water   squirtle.jpg\n",
       "1    wartortle   Water  wartortle.jpg\n",
       "2    blastoise   Water  blastoise.jpg\n",
       "3      psyduck   Water    psyduck.jpg\n",
       "4      golduck   Water    golduck.jpg\n",
       "..         ...     ...            ...\n",
       "804  naganadel  Others  naganadel.jpg\n",
       "805  stakataka  Others  stakataka.jpg\n",
       "806    zeraora  Others    zeraora.jpg\n",
       "807     meltan  Others     meltan.jpg\n",
       "808   melmetal  Others   melmetal.jpg\n",
       "\n",
       "[809 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk_types_df['Pokemon Image'] = sorted_imgs\n",
    "pk_types_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando imagens em Treino, Validação e Teste\n",
    "\n",
    "Nesse passo, fazemos a divisão das imagens para treino, validação e teste. Primeiro fazemos a divisão 0.8/0.2 entre treino e teste. Depois, fazemos outra divisão 0.8/0.2, mas dessa vez pra dividir os dados de treino, gerados no primeiro split, entre dados de treino e dados de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('train/'):\n",
    "    os.mkdir('train/')\n",
    "else:\n",
    "    rmtree('train/')\n",
    "    os.mkdir('train/') \n",
    "\n",
    "if not os.path.exists('val/'):\n",
    "    os.mkdir('val/')\n",
    "else:\n",
    "    rmtree('val/')\n",
    "    os.mkdir('val/') \n",
    "\n",
    "if not os.path.exists('test/'):\n",
    "    os.mkdir('test/')\n",
    "else:\n",
    "    rmtree('test/')\n",
    "    os.mkdir('test/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pk_type in pk_types_df.Type.unique():\n",
    "    if not os.path.exists(f'train/{pk_type}/'):\n",
    "        os.mkdir('train/'+str(pk_type)+'/')\n",
    "    if not os.path.exists(f'val/{pk_type}/'):\n",
    "        os.mkdir('val/'+str(pk_type)+'/')\n",
    "    if not os.path.exists(f'test/'):\n",
    "        os.mkdir('test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(pk_types_df['Pokemon Image'], pk_types_df.Type, \n",
    "                                                    test_size=0.2, stratify=pk_types_df.Type, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, \n",
    "                                                    test_size=0.2, stratify=y_train_val, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for from_path, to_path in zip(X_train.values, y_train.values):\n",
    "    if os.path.exists( f'train/{to_path}'):\n",
    "        copy2(f'converted_images/{from_path}', f'train/{to_path}/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for from_path, to_path in zip(X_test.values, y_test.values):\n",
    "    copy2(f'converted_images/{from_path}', f'test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for from_path, to_path in zip(X_val.values, y_val.values):\n",
    "    if os.path.exists( f'val/{to_path}'):\n",
    "        copy2(f'converted_images/{from_path}', f'val/{to_path}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Devido à baixa quantidade de amostras do dataset (809 amostras), utilizamos o método ImageDataGenerator para fazer Data Augmentation em tempo real. Mais detalhes sobre o método em https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 517 images belonging to 4 classes.\n",
      "Found 130 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=40, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=.2, \n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "train_generator = train_datagen.flow_from_directory('train/', \n",
    "                                                    target_size = (64, 64), \n",
    "                                                    class_mode='categorical', \n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory('val/', \n",
    "                                                  target_size = (64, 64),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando CNNs\n",
    "\n",
    "Testamos uma Rede Neural Convolucional com apenas duas camadas de Convolução, com ReLu como retificador, e cada uma dessas camadas seguidas por uma camada de MaxPooling. Além disso, incluímos Dropouts, Flatten e duas camadas densas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,625,668\n",
      "Trainable params: 1,625,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 2s 117ms/step - loss: 0.8898 - accuracy: 0.6460 - val_loss: 0.9276 - val_accuracy: 0.6769\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 128ms/step - loss: 0.8885 - accuracy: 0.6557 - val_loss: 0.9007 - val_accuracy: 0.6846\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.8905 - accuracy: 0.6480 - val_loss: 0.9037 - val_accuracy: 0.7000\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.8885 - accuracy: 0.6499 - val_loss: 0.9285 - val_accuracy: 0.6692\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.8750 - accuracy: 0.6499 - val_loss: 0.8974 - val_accuracy: 0.6923\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.8993 - accuracy: 0.6673 - val_loss: 0.8911 - val_accuracy: 0.7077\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.8741 - accuracy: 0.6518 - val_loss: 0.8981 - val_accuracy: 0.6846\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.8823 - accuracy: 0.6557 - val_loss: 0.9044 - val_accuracy: 0.6923\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 114ms/step - loss: 0.8796 - accuracy: 0.6615 - val_loss: 0.9265 - val_accuracy: 0.6846\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 0.8760 - accuracy: 0.6596 - val_loss: 0.9096 - val_accuracy: 0.7077\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.8798 - accuracy: 0.6770 - val_loss: 0.9067 - val_accuracy: 0.7154\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 103ms/step - loss: 0.8610 - accuracy: 0.6634 - val_loss: 0.8873 - val_accuracy: 0.7000\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.8513 - accuracy: 0.6789 - val_loss: 0.9104 - val_accuracy: 0.6769\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.8760 - accuracy: 0.6344 - val_loss: 0.9658 - val_accuracy: 0.6692\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.8546 - accuracy: 0.6557 - val_loss: 0.9325 - val_accuracy: 0.6769\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.8658 - accuracy: 0.6634 - val_loss: 0.9023 - val_accuracy: 0.6846\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.8803 - accuracy: 0.6615 - val_loss: 0.9044 - val_accuracy: 0.6846\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.8730 - accuracy: 0.6712 - val_loss: 0.9160 - val_accuracy: 0.6923\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.8493 - accuracy: 0.6654 - val_loss: 0.9156 - val_accuracy: 0.6923\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.9030 - accuracy: 0.6499 - val_loss: 0.8993 - val_accuracy: 0.6769\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.8920 - accuracy: 0.6538 - val_loss: 0.8973 - val_accuracy: 0.6846\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.8571 - accuracy: 0.6576 - val_loss: 0.8880 - val_accuracy: 0.6769\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.8575 - accuracy: 0.6654 - val_loss: 0.9491 - val_accuracy: 0.6846\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.8567 - accuracy: 0.6847 - val_loss: 0.9914 - val_accuracy: 0.6538\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.8505 - accuracy: 0.6518 - val_loss: 0.8870 - val_accuracy: 0.6923\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.8834 - accuracy: 0.6480 - val_loss: 0.9003 - val_accuracy: 0.6923\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 0.8568 - accuracy: 0.6750 - val_loss: 0.9042 - val_accuracy: 0.7000\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.8571 - accuracy: 0.6654 - val_loss: 0.9570 - val_accuracy: 0.6846\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 104ms/step - loss: 0.8477 - accuracy: 0.6576 - val_loss: 0.9429 - val_accuracy: 0.6769\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 2s 105ms/step - loss: 0.8588 - accuracy: 0.6654 - val_loss: 0.9071 - val_accuracy: 0.6846\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "          epochs = 30,\n",
    "          validation_data = val_generator);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao fim das 30 épocas, obtivemos acurácia de 66.54% para os dados de treinamento e 68.46% para o conjunto de validação. Um fator determinante para a acurácia não tão alta, é justamente a baixa quantidade de dados iniciais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o Modelo em algumas imagens do conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "\n",
    "def predict_image(filepath):\n",
    "    test_image = image.load_img(filepath, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = np.round(model.predict(test_image))\n",
    "    \n",
    "    if result[0][0] == 1:\n",
    "        prediction = \"Fire\"\n",
    "    elif result [0][1] == 1:\n",
    "        prediction = \"Normal\"\n",
    "    elif result [0][2] == 1:\n",
    "        prediction = \"Others\"\n",
    "    else:\n",
    "        prediction = \"Water\"\n",
    "    \n",
    "    img_path = filepath.split('/')[1]\n",
    "    correct_type = pk_types_df.loc[pk_types_df[\"Pokemon Image\"] == img_path].Type.values[0]\n",
    "    \n",
    "    print(f\"Expected Type: {correct_type}\\nPredict Type: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Type: Water\n",
      "Predict Type: Water\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image('test/vaporeon.jpg')\n",
    "Image('test/vaporeon.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Type: Others\n",
      "Predict Type: Others\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image('test/muk.jpg')\n",
    "Image('test/muk.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
